"""add user schema per ds

Revision ID: d2af7a7ec064
Revises: 3ec67dfd9ae6
Create Date: 2025-09-25 10:41:10.810101

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = 'd2af7a7ec064'
down_revision: Union[str, None] = '3ec67dfd9ae6'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('user_data_source_tables',
    sa.Column('data_source_id', sa.String(length=36), nullable=False),
    sa.Column('user_id', sa.String(length=36), nullable=False),
    sa.Column('table_name', sa.String(), nullable=False),
    sa.Column('data_source_table_id', sa.String(length=36), nullable=True),
    sa.Column('is_accessible', sa.Boolean(), nullable=False),
    sa.Column('status', sa.String(), nullable=False),
    sa.Column('metadata_json', sa.JSON(), nullable=True),
    sa.Column('id', sa.String(length=36), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.Column('deleted_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['data_source_id'], ['data_sources.id'], ),
    sa.ForeignKeyConstraint(['data_source_table_id'], ['datasource_tables.id'], ),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('data_source_id', 'user_id', 'table_name', name='uq_user_ds_table')
    )
    with op.batch_alter_table('user_data_source_tables', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_user_data_source_tables_data_source_id'), ['data_source_id'], unique=False)
        batch_op.create_index(batch_op.f('ix_user_data_source_tables_id'), ['id'], unique=True)
        batch_op.create_index(batch_op.f('ix_user_data_source_tables_user_id'), ['user_id'], unique=False)

    op.create_table('user_data_source_columns',
    sa.Column('user_data_source_table_id', sa.String(length=36), nullable=False),
    sa.Column('column_name', sa.String(), nullable=False),
    sa.Column('is_accessible', sa.Boolean(), nullable=False),
    sa.Column('is_masked', sa.Boolean(), nullable=False),
    sa.Column('data_type', sa.String(), nullable=True),
    sa.Column('id', sa.String(length=36), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.Column('deleted_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['user_data_source_table_id'], ['user_data_source_tables.id'], ),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('user_data_source_table_id', 'column_name', name='uq_user_ds_table_column')
    )
    with op.batch_alter_table('user_data_source_columns', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_user_data_source_columns_id'), ['id'], unique=True)
        batch_op.create_index(batch_op.f('ix_user_data_source_columns_user_data_source_table_id'), ['user_data_source_table_id'], unique=False)



def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
   
    with op.batch_alter_table('user_data_source_columns', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_user_data_source_columns_user_data_source_table_id'))
        batch_op.drop_index(batch_op.f('ix_user_data_source_columns_id'))

    op.drop_table('user_data_source_columns')
    with op.batch_alter_table('user_data_source_tables', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_user_data_source_tables_user_id'))
        batch_op.drop_index(batch_op.f('ix_user_data_source_tables_id'))
        batch_op.drop_index(batch_op.f('ix_user_data_source_tables_data_source_id'))

    op.drop_table('user_data_source_tables')
    # ### end Alembic commands ###
